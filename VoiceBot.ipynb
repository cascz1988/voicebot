{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58143c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download es_core_news_md -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da4b291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from nltk.corpus  import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertModel\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "spell = SpellChecker(language='es')\n",
    "\n",
    "def minusculas(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def lematizar(texto):\n",
    "    doc = nlp(texto)\n",
    "    lemas = ' '.join([token.lemma_ for token in doc])\n",
    "    return lemas\n",
    "\n",
    "def signos_puntuacion(text):\n",
    "    # Sustituir acentos por letras sin acentos\n",
    "    text = re.sub(r'[áäâà]', 'a', text)\n",
    "    text = re.sub(r'[éêèë]', 'e', text)\n",
    "    text = re.sub(r'[íîìï]', 'i', text)\n",
    "    text = re.sub(r'[óôòö]', 'o', text)\n",
    "    text = re.sub(r'[úûùü]', 'u', text)\n",
    "    # Eliminar signos de puntuación\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    words = text.split()\n",
    "    filtered_text = []\n",
    "    for word in words:\n",
    "        if word.lower() not in stop_words:\n",
    "            filtered_text.append(word)\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "# Función para corregir el texto\n",
    "def corregir_texto(texto):\n",
    "    palabras = texto.split()\n",
    "    #corregido = [spell.correction(palabra) for palabra in palabras]\n",
    "    corregido = [spell.correction(palabra) if spell.correction(palabra) is not None else palabra for palabra in palabras]\n",
    "    texto_corregido = ' '.join(corregido)\n",
    "    return texto_corregido\n",
    "\n",
    "# Definir la clase FineTuningBERT\n",
    "class FineTuningBERT(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(FineTuningBERT, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(bert.config.hidden_size, 64)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 93)\n",
    "\n",
    "        # Agregar la capa faltante para position_ids\n",
    "        self.position_ids = nn.Embedding(bert.config.max_position_embeddings, bert.config.hidden_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_hs = outputs['pooler_output']\n",
    "\n",
    "        x = self.dropout(cls_hs)\n",
    "        x = self.fc1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b1a0764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ruta_modelo = 'modelo-clasficacion-preguntas-planetas.pth'\n",
    "ruta_tokenizador = 'tokenizer-clasficacion-preguntas-planetas'\n",
    "\n",
    "# Inicializar el modelo BERT pre-entrenado\n",
    "bert_model = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", return_dict=True)\n",
    "\n",
    "# Inicializar el modelo FineTuningBERT\n",
    "model = FineTuningBERT(bert_model)\n",
    "# Cargar los pesos del modelo guardados\n",
    "model.load_state_dict(torch.load(ruta_modelo), strict=False)  # strict=False para omitir las claves faltantes\n",
    "# Cargar el tokenizer desde su directorio\n",
    "tokenizer = BertTokenizer.from_pretrained(ruta_tokenizador)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f183c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datosChat.csv\")\n",
    "# Creamos un objeto LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Convertimos las etiquetas de texto a números enteros\n",
    "df['label_codigo'] = label_encoder.fit_transform(df['label'])\n",
    "# Obtenemos la correspondencia entre números y etiquetas\n",
    "label_dict = {i: label for i, label in enumerate(label_encoder.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc463ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que encapsula el procesamiento y la predicción\n",
    "def procesar_y_predecir(texto_ejemplo, tokenizer = tokenizer, model=model , label_dict = label_dict):\n",
    "    texto_procesado = minusculas(texto_ejemplo)\n",
    "    texto_procesado = signos_puntuacion(texto_procesado)\n",
    "    texto_procesado = corregir_texto(texto_procesado)\n",
    "    texto_procesado = lematizar(texto_procesado)\n",
    "    texto_procesado = remove_stop_words(texto_procesado)\n",
    "\n",
    "    inputs = tokenizer(texto_procesado, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "\n",
    "    predicted_label_id = torch.argmax(outputs, dim=1).item()\n",
    "    predicted_probability = probabilities[0][predicted_label_id].item()\n",
    "\n",
    "    print(\"Texto de ejemplo original:\", texto_ejemplo)\n",
    "    print(\"Texto de ejemplo procesado:\", texto_procesado)\n",
    "    print(\"Clase predicha:\", label_dict[predicted_label_id])\n",
    "    #print(f\"Score: {predicted_probability:.2f}\")\n",
    "    \n",
    "    if predicted_probability >= .06:\n",
    "        \n",
    "        all_probabilities = probabilities[0].tolist()\n",
    "        max_probability = max(all_probabilities)\n",
    "        sorted_indexes = sorted(range(len(all_probabilities)), key=lambda k: all_probabilities[k], reverse=True)\n",
    "    \n",
    "        top_n = 5\n",
    "        for i, idx in enumerate(sorted_indexes[:top_n], 1):\n",
    "            probability = all_probabilities[idx]\n",
    "            percentage = (probability / max_probability) * 100 if max_probability > 0 else 0\n",
    "            #print(f\"score {probability:.2f} de la opcion {i}, porcentaje: {percentage:.0f}%, Índice de etiqueta: {idx}, Etiqueta: {label_dict[idx]}\")\n",
    "        # Filtrar el DataFrame para obtener las filas con la etiqueta predicha\n",
    "        filas_etiqueta_predicha = df[df['label_codigo'] == predicted_label_id]\n",
    "        # Seleccionar aleatoriamente una fila\n",
    "        fila_aleatoria = filas_etiqueta_predicha.sample(n=1)\n",
    "        # Obtener el valor de la columna 'respuesta' de la fila seleccionada\n",
    "        respuesta = fila_aleatoria['respuesta'].values[0]\n",
    "        #print(\"Respuesta correspondiente a la etiqueta predicha:\")\n",
    "    else:\n",
    "        respuesta = \"Por favor, vuelva a hacer la solicitud.\"\n",
    "    #print(respuesta)\n",
    "    return respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "597ea6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import pyttsx3\n",
    "\n",
    "# Inicializar el reconocedor de voz\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Configuración del motor de texto a voz\n",
    "def convert_text_to_audio(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 170) \n",
    "    engine.setProperty('voice', 'spanish')\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Función para procesar la solicitud de voz\n",
    "def process_voice_request(button):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        if button.description == 'Iniciar conversacion':\n",
    "            button.description = 'Procesando solicitud de voz'\n",
    "            # Activar el reconocimiento de voz\n",
    "            with sr.Microphone() as source:\n",
    "                print(\"Te escucho...\")\n",
    "                recognizer.adjust_for_ambient_noise(source)\n",
    "                #audio = recognizer.listen(source)\n",
    "                audio = recognizer.listen(source, timeout=2)\n",
    "            try:\n",
    "                # Reconocer el audio y mostrar la respuesta\n",
    "                text = recognizer.recognize_google(audio, language='es-ES')\n",
    "                output_text = widgets.Label(\"Has dicho: \" + text.lower())\n",
    "                display(output_text)\n",
    "                # Procesar la solicitud\n",
    "                respuesta = procesar_y_predecir(text)\n",
    "                output_resp = widgets.Textarea(value=respuesta, disabled=False, layout={'height': 'auto', 'width': '50%'}, rows=3)\n",
    "                #output_resp = widgets.Label(\"Respuesta: \" + respuesta.lower())\n",
    "                # Establecer encabezado\n",
    "                output_resp_label = widgets.Label(value=\"Respuesta:\")\n",
    "                #display(output_resp)\n",
    "                display(output_resp_label, output_resp)\n",
    "                # Convertir texto a audio y reproducirlo\n",
    "                convert_text_to_audio(respuesta)\n",
    "                button.description = 'Nueva solicitud'\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"No se ha entendido lo que has dicho, vuelve a intentarlo...\")\n",
    "        else:\n",
    "            button.description = 'Iniciar conversacion'\n",
    "            clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17782ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6751f045847942598e883b176abb5b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xc8\\x00\\x00\\x01\\x02\\x08\\x06\\x00\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear el botón y el output\n",
    "button = widgets.Button(description='Iniciar conversacion', layout=widgets.Layout(width='250px'), button_style='info')\n",
    "output = widgets.Output()\n",
    "# Conectar la función con el evento \"on_click\" del botón\n",
    "button.on_click(process_voice_request)\n",
    "# Conectar la función con el evento \"on_click\" del botón\n",
    "button.on_click(process_voice_request)\n",
    "# Mostrar la imagen y el botón\n",
    "image_path = 'chatbot.png'\n",
    "image_widget = widgets.Image.from_file(image_path, layout=widgets.Layout(width='250px'))\n",
    "display(widgets.VBox([image_widget, button, output]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc387676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
